{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Benchmark Inference W/ Training and W/ ONNX (Exported from Pytorch) Using LeNet-5 Model On MNIST Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/connection.py\", line 159, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/util/connection.py\", line 80, in create_connection\n",
      "    raise err\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/util/connection.py\", line 70, in create_connection\n",
      "    sock.connect(sa)\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/http/client.py\", line 1244, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/http/client.py\", line 1290, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/http/client.py\", line 1239, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/http/client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/connection.py\", line 181, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/connection.py\", line 168, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ffa95369b90>: Failed to establish a new connection: [Errno 111] Connection refused\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/urllib3/util/retry.py\", line 399, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa95369b90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/visdom/__init__.py\", line 711, in _send\n",
      "    data=json.dumps(msg),\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/visdom/__init__.py\", line 677, in _handle_post\n",
      "    r = self.session.post(url, data=data)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/requests/sessions.py\", line 581, in post\n",
      "    return self.request('POST', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/marouenez/anaconda3/envs/masterthesis/lib/python3.7/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=8097): Max retries exceeded with url: /env/main (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ffa95369b90>: Failed to establish a new connection: [Errno 111] Connection refused'))\n",
      "[Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception in user code:\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    Input - 1x32x32\n",
    "    C1 - 6@28x28 (5x5 kernel)\n",
    "    tanh\n",
    "    S2 - 6@14x14 (2x2 kernel, stride 2) Subsampling\n",
    "    C3 - 16@10x10 (5x5 kernel, complicated shit)\n",
    "    tanh\n",
    "    S4 - 16@5x5 (2x2 kernel, stride 2) Subsampling\n",
    "    C5 - 120@1x1 (5x5 kernel)\n",
    "    F6 - 84\n",
    "    tanh\n",
    "    F7 - 10 (Output)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.convnet = nn.Sequential(OrderedDict([\n",
    "            ('c1', nn.Conv2d(1, 6, kernel_size=(5, 5))),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('s2', nn.MaxPool2d(kernel_size=(2, 2), stride=2)),\n",
    "            ('c3', nn.Conv2d(6, 16, kernel_size=(5, 5))),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('s4', nn.MaxPool2d(kernel_size=(2, 2), stride=2)),\n",
    "            ('c5', nn.Conv2d(16, 120, kernel_size=(5, 5))),\n",
    "            ('relu5', nn.ReLU())\n",
    "        ]))\n",
    "\n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('f6', nn.Linear(120, 84)),\n",
    "            ('relu6', nn.ReLU()),\n",
    "            ('f7', nn.Linear(84, 10)),\n",
    "            ('sig7', nn.LogSoftmax(dim=-1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.convnet(img)\n",
    "        output = output.view(img.size(0), -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "viz = visdom.Visdom()\n",
    "\n",
    "data_train = MNIST('../data/mnist',\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Resize((32, 32)),\n",
    "                       transforms.ToTensor()]))\n",
    "data_test = MNIST('../data',\n",
    "                  train=False,\n",
    "                  download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize((32, 32)),\n",
    "                      transforms.ToTensor()]))\n",
    "data_train_loader = DataLoader(data_train, batch_size=256, shuffle=True, num_workers=8)\n",
    "data_test_loader = DataLoader(data_test, batch_size=1024, num_workers=8)\n",
    "\n",
    "net = LeNet5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01, mome)\n",
    "\n",
    "cur_batch_win = None\n",
    "cur_batch_win_opts = {\n",
    "    'title': 'Epoch Loss Trace',\n",
    "    'xlabel': 'Batch Number',\n",
    "    'ylabel': 'Loss',\n",
    "    'width': 1200,\n",
    "    'height': 600,\n",
    "}\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global cur_batch_win\n",
    "    net.train()\n",
    "    loss_list, batch_list = [], []\n",
    "    for i, (images, labels) in enumerate(data_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = net(images)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss_list.append(loss.detach().cpu().item())\n",
    "        batch_list.append(i+1)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.detach().cpu().item()))\n",
    "\n",
    "        # Update Visualization\n",
    "        if viz.check_connection():\n",
    "            cur_batch_win = viz.line(torch.Tensor(loss_list), torch.Tensor(batch_list),\n",
    "                                     win=cur_batch_win, name='current_batch_loss',\n",
    "                                     update=(None if cur_batch_win is None else 'replace'),\n",
    "                                     opts=cur_batch_win_opts)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test():\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(data_test_loader):\n",
    "        output = net(images)\n",
    "        avg_loss += criterion(output, labels).sum()\n",
    "        pred = output.detach().max(1)[1]\n",
    "        total_correct += pred.eq(labels.view_as(pred)).sum()\n",
    "\n",
    "    avg_loss /= len(data_test)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.detach().cpu().item(), float(total_correct) / len(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch 1, Batch: 0, Loss: 2.303839\n",
      "Train - Epoch 1, Batch: 10, Loss: 2.045590\n",
      "Train - Epoch 1, Batch: 20, Loss: 0.982229\n",
      "Train - Epoch 1, Batch: 30, Loss: 0.613105\n",
      "Train - Epoch 1, Batch: 40, Loss: 0.483880\n",
      "Train - Epoch 1, Batch: 50, Loss: 0.510918\n",
      "Train - Epoch 1, Batch: 60, Loss: 0.442262\n",
      "Train - Epoch 1, Batch: 70, Loss: 0.365387\n",
      "Train - Epoch 1, Batch: 80, Loss: 0.332463\n",
      "Train - Epoch 1, Batch: 90, Loss: 0.269213\n",
      "Train - Epoch 1, Batch: 100, Loss: 0.268802\n",
      "Train - Epoch 1, Batch: 110, Loss: 0.308392\n",
      "Train - Epoch 1, Batch: 120, Loss: 0.251106\n",
      "Train - Epoch 1, Batch: 130, Loss: 0.194121\n",
      "Train - Epoch 1, Batch: 140, Loss: 0.207979\n",
      "Train - Epoch 1, Batch: 150, Loss: 0.152464\n",
      "Train - Epoch 1, Batch: 160, Loss: 0.186036\n",
      "Train - Epoch 1, Batch: 170, Loss: 0.158188\n",
      "Train - Epoch 1, Batch: 180, Loss: 0.158564\n",
      "Train - Epoch 1, Batch: 190, Loss: 0.183780\n",
      "Train - Epoch 1, Batch: 200, Loss: 0.144901\n",
      "Train - Epoch 1, Batch: 210, Loss: 0.111342\n",
      "Train - Epoch 1, Batch: 220, Loss: 0.230586\n",
      "Train - Epoch 1, Batch: 230, Loss: 0.167195\n",
      "Train - Epoch 2, Batch: 0, Loss: 0.127213\n",
      "Train - Epoch 2, Batch: 10, Loss: 0.150564\n",
      "Train - Epoch 2, Batch: 20, Loss: 0.093373\n",
      "Train - Epoch 2, Batch: 30, Loss: 0.102173\n",
      "Train - Epoch 2, Batch: 40, Loss: 0.121139\n",
      "Train - Epoch 2, Batch: 50, Loss: 0.130428\n",
      "Train - Epoch 2, Batch: 60, Loss: 0.067117\n",
      "Train - Epoch 2, Batch: 70, Loss: 0.127054\n",
      "Train - Epoch 2, Batch: 80, Loss: 0.132129\n",
      "Train - Epoch 2, Batch: 90, Loss: 0.055632\n",
      "Train - Epoch 2, Batch: 100, Loss: 0.074737\n",
      "Train - Epoch 2, Batch: 110, Loss: 0.095290\n",
      "Train - Epoch 2, Batch: 120, Loss: 0.055423\n",
      "Train - Epoch 2, Batch: 130, Loss: 0.082009\n",
      "Train - Epoch 2, Batch: 140, Loss: 0.062984\n",
      "Train - Epoch 2, Batch: 150, Loss: 0.147540\n",
      "Train - Epoch 2, Batch: 160, Loss: 0.054039\n",
      "Train - Epoch 2, Batch: 170, Loss: 0.047316\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, 16):\n",
    "    train(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "torch.save(net.state_dict(), 'output/mnist.pth')\n",
    "\n",
    "# Load the trained model from file\n",
    "trained_model = LeNet5()\n",
    "trained_model.load_state_dict(torch.load('output/mnist.pth'))\n",
    "\n",
    "# Export the trained model to ONNX\n",
    "dummy_input = Variable(torch.randn(1, 1, 32, 32)) # one black and white 28 x 28 picture will be the input to the model\n",
    "torch.onnx.export(trained_model, dummy_input, \"output/mnist_LeNet.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "# Load the ONNX file\n",
    "onnx_model = onnx.load('output/mnist_LeNet.onnx')\n",
    "\n",
    "# Import the ONNX model to Tensorflow\n",
    "tf_rep = prepare(onnx_model, strict= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def performance_tensorflow_model(model, inputs, warmup_iters=3, main_iters=10):\n",
    "    '''\n",
    "     Run the model several times, and measure the execution time.\n",
    "     Print the execution time per iteration (millisecond) and the number of iterations per second.\n",
    "    '''\n",
    "\n",
    "    for _i in range(warmup_iters):\n",
    "        output = tf_rep.run(inputs)\n",
    "    execution_time = []\n",
    "    total_time = 0.0\n",
    "    for _i in range(main_iters):\n",
    "        ts = time.time()\n",
    "        output = tf_rep.run(inputs)\n",
    "        te = time.time()\n",
    "        execution_time.append((te - ts)* 1000)\n",
    "        total_time += (te - ts)\n",
    "    print(\"The Tensorflow model execution time per iter is {} milliseconds, \"\n",
    "          \"{} iters per second.\".format(total_time / main_iters * 1000,\n",
    "                                        main_iters / total_time))\n",
    "    return execution_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "it = iter(data_test_loader)\n",
    "first = next(it)\n",
    "tensorflow_inputs = first[0][0].numpy().reshape(1,1,32,32)\n",
    "output = tf_rep.run(tensorflow_inputs)\n",
    "print(np.argmax(output), first[1][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "execution_time = performance_tensorflow_model(onnx_model, tensorflow_inputs, warmup_iters=3,main_iters=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(execution_time)\n",
    "plt.ylabel('Execution time in milliseconds per iteration')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Performance of Tensorflow Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
